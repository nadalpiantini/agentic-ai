# ============================================
# Agentic Hub - Environment Configuration
# ============================================
# Copy this file to .env.local and fill in your values
# NEVER commit .env.local to git!

# ============================================
# SUPABASE CONFIGURATION
# ============================================
# Get these from your Supabase project settings
# https://supabase.com/dashboard/project/_/settings/api

NEXT_PUBLIC_SUPABASE_URL=your-project-url.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key-here
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here

# Database connection string for checkpointer
# Format: postgresql://postgres:[password]@db.[project].supabase.co:5432/postgres
DATABASE_URL=postgresql://postgres:[password]@db.your-project.supabase.co:5432/postgres

# ============================================
# ANTHROPIC CLAUDE API
# ============================================
# Get your API key from: https://console.anthropic.com/
# Used for: High-quality reasoning, complex tasks, code generation

ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ============================================
# DEEPSEEK API
# ============================================
# Get your API key from: https://platform.deepseek.com/
# Used for: Cost-effective queries, simple tasks, high-volume operations

DEEPSEEK_API_KEY=your-deepseek-api-key-here

# ============================================
# OLLAMA (LOCAL MODEL)
# ============================================
# Ollama runs locally - no API key needed
# Default: http://localhost:11434
# Make sure Ollama is running: ollama serve

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ============================================
# OPENAI EMBEDDINGS (for RAG)
# ============================================
# Get your API key from: https://platform.openai.com/api-keys
# Used for: Vector embeddings in semantic search

OPENAI_API_KEY=your-openai-api-key-here

# ============================================
# AGENT CONFIGURATION
# ============================================
# Default model selection: claude | deepseek | ollama | auto
DEFAULT_MODEL=auto

# Maximum LLM calls before loop guard triggers (prevents infinite loops)
MAX_LLM_CALLS=25

# Maximum recursion depth for graph execution
MAX_RECURSION_DEPTH=10

# ============================================
# NEXT.JS CONFIGURATION
# ============================================
# Node environment
NODE_ENV=development

# ============================================
# OPTIONAL: MONITORING & ANALYTICS
# ============================================
# Uncomment if you want to add monitoring

# # Sentry for error tracking
# NEXT_PUBLIC_SENTRY_DSN=your-sentry-dsn
# SENTRY_AUTH_TOKEN=your-sentry-auth-token

# # Vercel Analytics
# NEXT_PUBLIC_VERCEL_ANALYTICS_ID=your-vercel-id
